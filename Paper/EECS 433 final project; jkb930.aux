\relax 
\citation{data}
\citation{paper}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Explanatory Variables}}{5}}
\newlabel{Explanatory Variables}{{1}{5}}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction \& Motivation}{5}}
\newlabel{introduction}{{1}{5}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Problem Description}{5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Description of the Data}{5}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Receiver Operating Characteristic}}{6}}
\newlabel{ROC area under curve}{{1}{6}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Confusion Matrix - KNN}}{7}}
\newlabel{Confusion Matrix - KNN}{{2}{7}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Measuring Model Accuracy}{7}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Not all Misclassifications are Equal}{7}}
\citation{Mitchell}
\citation{textbook}
\citation{code}
\@writefile{toc}{\contentsline {section}{\numberline {3}Baseline Methods}{8}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Classification Tree}{8}}
\citation{ML textbook}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Baseline Decision Tree}}{9}}
\newlabel{Baseline Decision Tree}{{3}{9}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}K-Nearest Neighbor}{9}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Logistic Regression}{9}}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces KNN k-values and Error Rates; Euclidean distance}}{10}}
\newlabel{KNN k-values and Error Rates}{{2}{10}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4}Discriminant Analysis}{10}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5}Naive Bayesian}{10}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Improvements}{10}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Feature Selection}{10}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Decision Tree after Feature Augmentation; Ratio\_1 and Ratio\_2 added}}{11}}
\newlabel{Decision Tree after Feature augmentation}{{4}{11}}
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces Feature Selection Results - 23 versus 25 explanatory variables}}{11}}
\newlabel{Feature Selection Results}{{3}{11}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Avoid Overfitting by Mandating Minimum Leaf Size}{11}}
\citation{ML textbook}
\@writefile{lot}{\contentsline {table}{\numberline {4}{\ignorespaces 10-fold cross validation}}{12}}
\newlabel{10-fold cross validation}{{4}{12}}
\@writefile{lot}{\contentsline {table}{\numberline {5}{\ignorespaces PCA Results}}{12}}
\newlabel{PCA Results}{{5}{12}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}K-fold Cross Validation}{12}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4}Principal Component Analysis}{12}}
\bibcite{data}{1}
\bibcite{paper}{2}
\bibcite{Mitchell}{3}
\bibcite{textbook}{4}
\@writefile{lot}{\contentsline {table}{\numberline {6}{\ignorespaces Classifier Performance}}{13}}
\newlabel{Classifier Performance}{{6}{13}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Conclusion}{13}}
\@writefile{toc}{\contentsline {section}{\numberline {6}Course Feedback}{13}}
\@writefile{toc}{\contentsline {section}{\numberline {7}Addendum}{13}}
\bibcite{ML textbook}{5}
